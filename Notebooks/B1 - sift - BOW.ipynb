{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3.1\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#print('OpenCV Version (should be 3.1.0, with nonfree packages installed, for this tutorial):')\n",
    "print(cv2.__version__)\n",
    "import PIL\n",
    "from PIL import Image, ImageOps\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "%matplotlib inline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from PIL import ImageFilter\n",
    "from skimage.restoration import estimate_sigma, denoise_nl_means\n",
    "from skimage.filters import gaussian\n",
    "from skimage import exposure\n",
    "from skimage import img_as_ubyte, img_as_float\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some links..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.pyimagesearch.com/2014/05/26/opencv-python-k-means-color-clustering/  \n",
    "http://charlesleifer.com/blog/using-python-and-k-means-to-find-the-dominant-colors-in-images/  \n",
    "https://docs.opencv.org/3.0-beta/doc/py_tutorials/py_ml/py_kmeans/py_kmeans_opencv/py_kmeans_opencv.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>breed</th>\n",
       "      <th>file</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "      <th>foldername</th>\n",
       "      <th>filename</th>\n",
       "      <th>dog_number</th>\n",
       "      <th>prepfilename</th>\n",
       "      <th>xdelta</th>\n",
       "      <th>ydelta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>n02085620_10074</th>\n",
       "      <td>Chihuahua</td>\n",
       "      <td>n02085620_10074</td>\n",
       "      <td>25.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>498.0</td>\n",
       "      <td>02085620</td>\n",
       "      <td>n02085620_10074</td>\n",
       "      <td>1</td>\n",
       "      <td>n02085620_10074-Chihuahua_cr1</td>\n",
       "      <td>251.0</td>\n",
       "      <td>488.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n02085620_10131</th>\n",
       "      <td>Chihuahua</td>\n",
       "      <td>n02085620_10131</td>\n",
       "      <td>49.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>393.0</td>\n",
       "      <td>493.0</td>\n",
       "      <td>02085620</td>\n",
       "      <td>n02085620_10131</td>\n",
       "      <td>1</td>\n",
       "      <td>n02085620_10131-Chihuahua_cr1</td>\n",
       "      <td>344.0</td>\n",
       "      <td>484.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n02085620_10621</th>\n",
       "      <td>Chihuahua</td>\n",
       "      <td>n02085620_10621</td>\n",
       "      <td>142.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>335.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>02085620</td>\n",
       "      <td>n02085620_10621</td>\n",
       "      <td>1</td>\n",
       "      <td>n02085620_10621-Chihuahua_cr1</td>\n",
       "      <td>193.0</td>\n",
       "      <td>207.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n02085620_1073</th>\n",
       "      <td>Chihuahua</td>\n",
       "      <td>n02085620_1073</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>498.0</td>\n",
       "      <td>02085620</td>\n",
       "      <td>n02085620_1073</td>\n",
       "      <td>1</td>\n",
       "      <td>n02085620_1073-Chihuahua_cr1</td>\n",
       "      <td>312.0</td>\n",
       "      <td>471.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n02085620_10976</th>\n",
       "      <td>Chihuahua</td>\n",
       "      <td>n02085620_10976</td>\n",
       "      <td>90.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>452.0</td>\n",
       "      <td>02085620</td>\n",
       "      <td>n02085620_10976</td>\n",
       "      <td>1</td>\n",
       "      <td>n02085620_10976-Chihuahua_cr1</td>\n",
       "      <td>152.0</td>\n",
       "      <td>348.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     breed             file   xmin   ymin   xmax   ymax  \\\n",
       "n02085620_10074  Chihuahua  n02085620_10074   25.0   10.0  276.0  498.0   \n",
       "n02085620_10131  Chihuahua  n02085620_10131   49.0    9.0  393.0  493.0   \n",
       "n02085620_10621  Chihuahua  n02085620_10621  142.0   43.0  335.0  250.0   \n",
       "n02085620_1073   Chihuahua   n02085620_1073    0.0   27.0  312.0  498.0   \n",
       "n02085620_10976  Chihuahua  n02085620_10976   90.0  104.0  242.0  452.0   \n",
       "\n",
       "                foldername         filename  dog_number  \\\n",
       "n02085620_10074   02085620  n02085620_10074           1   \n",
       "n02085620_10131   02085620  n02085620_10131           1   \n",
       "n02085620_10621   02085620  n02085620_10621           1   \n",
       "n02085620_1073    02085620   n02085620_1073           1   \n",
       "n02085620_10976   02085620  n02085620_10976           1   \n",
       "\n",
       "                                  prepfilename  xdelta  ydelta  \n",
       "n02085620_10074  n02085620_10074-Chihuahua_cr1   251.0   488.0  \n",
       "n02085620_10131  n02085620_10131-Chihuahua_cr1   344.0   484.0  \n",
       "n02085620_10621  n02085620_10621-Chihuahua_cr1   193.0   207.0  \n",
       "n02085620_1073    n02085620_1073-Chihuahua_cr1   312.0   471.0  \n",
       "n02085620_10976  n02085620_10976-Chihuahua_cr1   152.0   348.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('Z1-picture_cropping.csv', index_col=0, dtype={'foldername':'object'})\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Afghan_hound' 'African_hunting_dog' 'Airedale'\n",
      " 'American_Staffordshire_terrier' 'Appenzeller' 'Australian_terrier'\n",
      " 'Bedlington_terrier' 'Bernese_mountain_dog' 'Blenheim_spaniel'\n",
      " 'Border_collie' 'Border_terrier' 'Boston_bull' 'Bouvier_des_Flandres'\n",
      " 'Brabancon_griffon' 'Brittany_spaniel' 'Cardigan'\n",
      " 'Chesapeake_Bay_retriever' 'Chihuahua' 'Dandie_Dinmont' 'Doberman'\n",
      " 'English_foxhound' 'English_setter' 'English_springer' 'EntleBucher'\n",
      " 'Eskimo_dog' 'French_bulldog' 'German_shepherd'\n",
      " 'German_short-haired_pointer' 'Gordon_setter' 'Great_Dane'\n",
      " 'Great_Pyrenees' 'Greater_Swiss_Mountain_dog' 'Ibizan_hound'\n",
      " 'Irish_setter' 'Irish_terrier' 'Irish_water_spaniel' 'Irish_wolfhound'\n",
      " 'Italian_greyhound' 'Japanese_spaniel' 'Kerry_blue_terrier'\n",
      " 'Labrador_retriever' 'Lakeland_terrier' 'Leonberg' 'Lhasa' 'Maltese_dog'\n",
      " 'Mexican_hairless' 'Newfoundland' 'Norfolk_terrier' 'Norwegian_elkhound'\n",
      " 'Norwich_terrier' 'Old_English_sheepdog' 'Pekinese' 'Pembroke'\n",
      " 'Pomeranian' 'Rhodesian_ridgeback' 'Rottweiler' 'Saint_Bernard' 'Saluki'\n",
      " 'Samoyed' 'Scotch_terrier' 'Scottish_deerhound' 'Sealyham_terrier'\n",
      " 'Shetland_sheepdog' 'Shih-Tzu' 'Siberian_husky'\n",
      " 'Staffordshire_bullterrier' 'Sussex_spaniel' 'Tibetan_mastiff'\n",
      " 'Tibetan_terrier' 'Walker_hound' 'Weimaraner' 'Welsh_springer_spaniel'\n",
      " 'West_Highland_white_terrier' 'Yorkshire_terrier' 'affenpinscher'\n",
      " 'basenji' 'basset' 'beagle' 'black-and-tan_coonhound' 'bloodhound'\n",
      " 'bluetick' 'borzoi' 'boxer' 'briard' 'bull_mastiff' 'cairn' 'chow'\n",
      " 'clumber' 'cocker_spaniel' 'collie' 'curly-coated_retriever' 'dhole'\n",
      " 'dingo' 'flat-coated_retriever' 'giant_schnauzer' 'golden_retriever'\n",
      " 'groenendael' 'keeshond' 'kelpie' 'komondor' 'kuvasz' 'malamute'\n",
      " 'malinois' 'miniature_pinscher' 'miniature_poodle' 'miniature_schnauzer'\n",
      " 'otterhound' 'papillon' 'pug' 'redbone' 'schipperke' 'silky_terrier'\n",
      " 'soft-coated_wheaten_terrier' 'standard_poodle' 'standard_schnauzer'\n",
      " 'toy_poodle' 'toy_terrier' 'vizsla' 'whippet' 'wire-haired_fox_terrier']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>breed</th>\n",
       "      <th>file</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "      <th>foldername</th>\n",
       "      <th>filename</th>\n",
       "      <th>dog_number</th>\n",
       "      <th>prepfilename</th>\n",
       "      <th>xdelta</th>\n",
       "      <th>ydelta</th>\n",
       "      <th>breed_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>n02085620_10074</th>\n",
       "      <td>Chihuahua</td>\n",
       "      <td>n02085620_10074</td>\n",
       "      <td>25.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>498.0</td>\n",
       "      <td>02085620</td>\n",
       "      <td>n02085620_10074</td>\n",
       "      <td>1</td>\n",
       "      <td>n02085620_10074-Chihuahua_cr1</td>\n",
       "      <td>251.0</td>\n",
       "      <td>488.0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n02085620_10131</th>\n",
       "      <td>Chihuahua</td>\n",
       "      <td>n02085620_10131</td>\n",
       "      <td>49.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>393.0</td>\n",
       "      <td>493.0</td>\n",
       "      <td>02085620</td>\n",
       "      <td>n02085620_10131</td>\n",
       "      <td>1</td>\n",
       "      <td>n02085620_10131-Chihuahua_cr1</td>\n",
       "      <td>344.0</td>\n",
       "      <td>484.0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n02085620_10621</th>\n",
       "      <td>Chihuahua</td>\n",
       "      <td>n02085620_10621</td>\n",
       "      <td>142.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>335.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>02085620</td>\n",
       "      <td>n02085620_10621</td>\n",
       "      <td>1</td>\n",
       "      <td>n02085620_10621-Chihuahua_cr1</td>\n",
       "      <td>193.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n02085620_1073</th>\n",
       "      <td>Chihuahua</td>\n",
       "      <td>n02085620_1073</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>498.0</td>\n",
       "      <td>02085620</td>\n",
       "      <td>n02085620_1073</td>\n",
       "      <td>1</td>\n",
       "      <td>n02085620_1073-Chihuahua_cr1</td>\n",
       "      <td>312.0</td>\n",
       "      <td>471.0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n02085620_10976</th>\n",
       "      <td>Chihuahua</td>\n",
       "      <td>n02085620_10976</td>\n",
       "      <td>90.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>452.0</td>\n",
       "      <td>02085620</td>\n",
       "      <td>n02085620_10976</td>\n",
       "      <td>1</td>\n",
       "      <td>n02085620_10976-Chihuahua_cr1</td>\n",
       "      <td>152.0</td>\n",
       "      <td>348.0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     breed             file   xmin   ymin   xmax   ymax  \\\n",
       "n02085620_10074  Chihuahua  n02085620_10074   25.0   10.0  276.0  498.0   \n",
       "n02085620_10131  Chihuahua  n02085620_10131   49.0    9.0  393.0  493.0   \n",
       "n02085620_10621  Chihuahua  n02085620_10621  142.0   43.0  335.0  250.0   \n",
       "n02085620_1073   Chihuahua   n02085620_1073    0.0   27.0  312.0  498.0   \n",
       "n02085620_10976  Chihuahua  n02085620_10976   90.0  104.0  242.0  452.0   \n",
       "\n",
       "                foldername         filename  dog_number  \\\n",
       "n02085620_10074   02085620  n02085620_10074           1   \n",
       "n02085620_10131   02085620  n02085620_10131           1   \n",
       "n02085620_10621   02085620  n02085620_10621           1   \n",
       "n02085620_1073    02085620   n02085620_1073           1   \n",
       "n02085620_10976   02085620  n02085620_10976           1   \n",
       "\n",
       "                                  prepfilename  xdelta  ydelta  breed_code  \n",
       "n02085620_10074  n02085620_10074-Chihuahua_cr1   251.0   488.0          17  \n",
       "n02085620_10131  n02085620_10131-Chihuahua_cr1   344.0   484.0          17  \n",
       "n02085620_10621  n02085620_10621-Chihuahua_cr1   193.0   207.0          17  \n",
       "n02085620_1073    n02085620_1073-Chihuahua_cr1   312.0   471.0          17  \n",
       "n02085620_10976  n02085620_10976-Chihuahua_cr1   152.0   348.0          17  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(dataset['breed'])\n",
    "print(le.classes_)\n",
    "dataset['breed_code'] = le.transform(dataset['breed'])\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20580, 13)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset = dataset[dataset['breed_code'] <31]\n",
    "subset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>breed</th>\n",
       "      <th>file</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "      <th>foldername</th>\n",
       "      <th>filename</th>\n",
       "      <th>dog_number</th>\n",
       "      <th>prepfilename</th>\n",
       "      <th>xdelta</th>\n",
       "      <th>ydelta</th>\n",
       "      <th>breed_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>n02085620_10074</th>\n",
       "      <td>Chihuahua</td>\n",
       "      <td>n02085620_10074</td>\n",
       "      <td>25.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>498.0</td>\n",
       "      <td>02085620</td>\n",
       "      <td>n02085620_10074</td>\n",
       "      <td>1</td>\n",
       "      <td>n02085620_10074-Chihuahua_cr1</td>\n",
       "      <td>251.0</td>\n",
       "      <td>488.0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n02085620_10131</th>\n",
       "      <td>Chihuahua</td>\n",
       "      <td>n02085620_10131</td>\n",
       "      <td>49.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>393.0</td>\n",
       "      <td>493.0</td>\n",
       "      <td>02085620</td>\n",
       "      <td>n02085620_10131</td>\n",
       "      <td>1</td>\n",
       "      <td>n02085620_10131-Chihuahua_cr1</td>\n",
       "      <td>344.0</td>\n",
       "      <td>484.0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n02085620_10621</th>\n",
       "      <td>Chihuahua</td>\n",
       "      <td>n02085620_10621</td>\n",
       "      <td>142.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>335.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>02085620</td>\n",
       "      <td>n02085620_10621</td>\n",
       "      <td>1</td>\n",
       "      <td>n02085620_10621-Chihuahua_cr1</td>\n",
       "      <td>193.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n02085620_1073</th>\n",
       "      <td>Chihuahua</td>\n",
       "      <td>n02085620_1073</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>498.0</td>\n",
       "      <td>02085620</td>\n",
       "      <td>n02085620_1073</td>\n",
       "      <td>1</td>\n",
       "      <td>n02085620_1073-Chihuahua_cr1</td>\n",
       "      <td>312.0</td>\n",
       "      <td>471.0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n02085620_10976</th>\n",
       "      <td>Chihuahua</td>\n",
       "      <td>n02085620_10976</td>\n",
       "      <td>90.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>452.0</td>\n",
       "      <td>02085620</td>\n",
       "      <td>n02085620_10976</td>\n",
       "      <td>1</td>\n",
       "      <td>n02085620_10976-Chihuahua_cr1</td>\n",
       "      <td>152.0</td>\n",
       "      <td>348.0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     breed             file   xmin   ymin   xmax   ymax  \\\n",
       "n02085620_10074  Chihuahua  n02085620_10074   25.0   10.0  276.0  498.0   \n",
       "n02085620_10131  Chihuahua  n02085620_10131   49.0    9.0  393.0  493.0   \n",
       "n02085620_10621  Chihuahua  n02085620_10621  142.0   43.0  335.0  250.0   \n",
       "n02085620_1073   Chihuahua   n02085620_1073    0.0   27.0  312.0  498.0   \n",
       "n02085620_10976  Chihuahua  n02085620_10976   90.0  104.0  242.0  452.0   \n",
       "\n",
       "                foldername         filename  dog_number  \\\n",
       "n02085620_10074   02085620  n02085620_10074           1   \n",
       "n02085620_10131   02085620  n02085620_10131           1   \n",
       "n02085620_10621   02085620  n02085620_10621           1   \n",
       "n02085620_1073    02085620   n02085620_1073           1   \n",
       "n02085620_10976   02085620  n02085620_10976           1   \n",
       "\n",
       "                                  prepfilename  xdelta  ydelta  breed_code  \n",
       "n02085620_10074  n02085620_10074-Chihuahua_cr1   251.0   488.0          17  \n",
       "n02085620_10131  n02085620_10131-Chihuahua_cr1   344.0   484.0          17  \n",
       "n02085620_10621  n02085620_10621-Chihuahua_cr1   193.0   207.0          17  \n",
       "n02085620_1073    n02085620_1073-Chihuahua_cr1   312.0   471.0          17  \n",
       "n02085620_10976  n02085620_10976-Chihuahua_cr1   152.0   348.0          17  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Picture pre-loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cricket/anaconda3/lib/python3.6/site-packages/skimage/exposure/exposure.py:63: UserWarning: This might be a color image. The histogram will be computed on the flattened image. You can instead apply this function to each color channel.\n",
      "  warn(\"This might be a color image. The histogram will be \"\n"
     ]
    }
   ],
   "source": [
    "def pictureloader(picture):\n",
    "    patch_kw = dict(patch_size=5,      # 5x5 patches\n",
    "                        patch_distance=6,  # 13x13 search area\n",
    "                        multichannel=True)\n",
    "    \n",
    "    xmax = picture.xmax\n",
    "    ymax = picture.ymax\n",
    "    xmin = picture.xmin\n",
    "    ymin = picture.ymin\n",
    "    foldername = picture.foldername\n",
    "    breed = picture.breed\n",
    "    filename = picture.filename\n",
    "    prepfilename = picture.prepfilename\n",
    "        \n",
    "    #Image opening\n",
    "    img = Image.open('../Images/n{}-{}/{}.jpg'.format(foldername, breed, filename))\n",
    "            \n",
    "    #Image cropping\n",
    "    area = (xmin, ymin, xmax, ymax)\n",
    "    img = img.crop(area)\n",
    "            \n",
    "    #Image equalization\n",
    "    img = exposure.equalize_hist(np.array(img))\n",
    "            \n",
    "    #Gaussian blur fliter\n",
    "    sigma_est = np.mean(estimate_sigma(np.array(img), multichannel=True, average_sigmas=False))\n",
    "     \n",
    "    #Non linear mean\n",
    "    img = denoise_nl_means(img, h=1.5*sigma_est, fast_mode=True, **patch_kw)\n",
    "    #print(img)\n",
    "    return list(img)\n",
    "\n",
    "subset['Picture'] = subset.apply(pictureloader, axis=1).apply(np.array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset.to_csv('Z2 - dogs-breed-sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "n02085620_10074     (488, 251, 3)\n",
       "n02085620_10131     (484, 344, 3)\n",
       "n02085620_10621     (207, 193, 3)\n",
       "n02085620_1073      (471, 312, 3)\n",
       "n02085620_10976     (348, 152, 3)\n",
       "n02085620_11140     (215, 434, 3)\n",
       "n02085620_11238     (192, 106, 3)\n",
       "n02085620_11258     (345, 287, 3)\n",
       "n02085620_11337     (142, 170, 3)\n",
       "n02085620_11477     (364, 241, 3)\n",
       "n02085620_1152        (56, 46, 3)\n",
       "n02085620_11696     (516, 485, 3)\n",
       "n02085620_11818     (253, 181, 3)\n",
       "n02085620_11948     (420, 461, 3)\n",
       "n02085620_1205      (239, 204, 3)\n",
       "n02085620_12101     (248, 345, 3)\n",
       "n02085620_12334      (144, 91, 3)\n",
       "n02085620_1235       (188, 81, 3)\n",
       "n02085620_1271      (347, 305, 3)\n",
       "n02085620_12718     (445, 278, 3)\n",
       "n02085620_1298      (136, 287, 3)\n",
       "n02085620_13151     (304, 203, 3)\n",
       "n02085620_1321      (272, 137, 3)\n",
       "n02085620_13383     (256, 178, 3)\n",
       "n02085620_1346      (308, 431, 3)\n",
       "n02085620_13964     (362, 277, 3)\n",
       "n02085620_14252     (138, 180, 3)\n",
       "n02085620_14413     (727, 404, 3)\n",
       "n02085620_14516     (476, 436, 3)\n",
       "n02085620_1455      (345, 271, 3)\n",
       "                        ...      \n",
       "n02116738_8095       (100, 78, 3)\n",
       "n02116738_8226      (264, 334, 3)\n",
       "n02116738_8341      (289, 376, 3)\n",
       "n02116738_8403      (168, 123, 3)\n",
       "n02116738_8489      (209, 211, 3)\n",
       "n02116738_849       (142, 445, 3)\n",
       "n02116738_8512      (171, 165, 3)\n",
       "n02116738_8579      (145, 199, 3)\n",
       "n02116738_8653      (270, 299, 3)\n",
       "n02116738_8662       (135, 65, 3)\n",
       "n02116738_8669       (82, 127, 3)\n",
       "n02116738_8696      (210, 354, 3)\n",
       "n02116738_8719      (229, 249, 3)\n",
       "n02116738_8734      (185, 124, 3)\n",
       "n02116738_8738      (243, 180, 3)\n",
       "n02116738_8749      (381, 399, 3)\n",
       "n02116738_8945      (372, 284, 3)\n",
       "n02116738_9164      (129, 167, 3)\n",
       "n02116738_9232      (296, 220, 3)\n",
       "n02116738_9282      (330, 254, 3)\n",
       "n02116738_9333       (57, 166, 3)\n",
       "n02116738_9603     (755, 1147, 3)\n",
       "n02116738_9748      (188, 155, 3)\n",
       "n02116738_9762      (277, 213, 3)\n",
       "n02116738_9769      (150, 293, 3)\n",
       "n02116738_9798      (335, 491, 3)\n",
       "n02116738_9818      (332, 451, 3)\n",
       "n02116738_9829      (260, 170, 3)\n",
       "n02116738_9844      (194, 304, 3)\n",
       "n02116738_9924      (207, 206, 3)\n",
       "Name: Picture, Length: 20580, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset['Picture'].map(lambda x: x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(subset, subset['breed_code'], test_size=0.33, random_state=0, stratify=subset['breed_code'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cricket/anaconda3/lib/python3.6/site-packages/skimage/util/dtype.py:122: UserWarning: Possible precision loss when converting from float32 to uint8\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n",
      "/Users/cricket/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:29: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_minimum(a, axis, None, out, keepdims)\n",
      "/Users/cricket/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:26: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_maximum(a, axis, None, out, keepdims)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pictures loaded\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-380cb153ad22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0mdogreconizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSiftBOW\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'pics_save_pics'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'clf_apply_pca'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0mdogreconizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m \u001b[0mdogreconizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-24-380cb153ad22>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0msift_desc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor_dominance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_pics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_sift\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msift_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_colors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor_dominance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input arrays must have same number of dimensions"
     ]
    }
   ],
   "source": [
    "class SiftBOW(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, **params):        \n",
    "        self.kmeans_params = {'n_clusters':50, 'verbose':0, 'random_state':0, 'max_iter': 300}\n",
    "        self.sift_params = {'nfeatures':0}\n",
    "        self.pca_params = {'n_components':10, 'random_state':0}\n",
    "        self.cvect_params = {'ngram_range':(1,1), 'min_df':1, 'max_df':1.}\n",
    "        self.color_params = {'n_clusters':30, 'random_state':0, 'max_iter': 300}\n",
    "        self.pics_params = {'save_pics':True}\n",
    "        \n",
    "        self.clf_params = { 'kmean_sample_size':10000, 'apply_pca':True}\n",
    "        \n",
    "        self.params = {**{'kmeans_'+k:v for k,v in self.kmeans_params.items()},\n",
    "                       **{'sift_'+k:v for k,v in self.sift_params.items()},\n",
    "                       **{'cvect_'+k:v for k,v in self.cvect_params.items()},\n",
    "                       **{'clf_'+k:v for k,v in self.clf_params.items()},\n",
    "                       **{'pca_'+k:v for k,v in self.pca_params.items()},\n",
    "                       **{'color_'+k:v for k,v in self.color_params.items()},\n",
    "                       **{'pics_'+k:v for k,v in self.pics_params.items()},\n",
    "                       **params}\n",
    "        \n",
    "        self.update_params()\n",
    "        self.kmeans = KMeans(**self.kmeans_params)\n",
    "        self.scaler = StandardScaler()\n",
    "        self.color_scaler = StandardScaler()\n",
    "        self.cvect = CountVectorizer(**self.cvect_params, analyzer='word', tokenizer=None)\n",
    "        self.sift = cv2.xfeatures2d.SIFT_create(**self.sift_params)\n",
    "        #self.sift = cv2.ORB()\n",
    "        self.pca = PCA(**self.pca_params)\n",
    "        self.color_kmeans = KMeans(**self.color_params)\n",
    "        \n",
    "    def get_params(self, deep=True):\n",
    "        return self.params\n",
    "    \n",
    "    def set_params(self, **params):\n",
    "        self.params = {**self.params, **params}\n",
    "        self.update_params()\n",
    "        return self\n",
    "        \n",
    "    def update_params(self):\n",
    "        \n",
    "        self.kmeans_params = {k[7:]:v for k,v in self.params.items() if k.startswith('kmeans_')}\n",
    "        self.sift_params = {k[5:]:v for k,v in self.params.items() if k.startswith('sift_')}\n",
    "        self.pics_params = {k[5:]:v for k,v in self.params.items() if k.startswith('pics_')}\n",
    "        self.color_params = {k[6:]:v for k,v in self.params.items() if k.startswith('color_')}\n",
    "        self.cvect_params = {k[6:]:v for k,v in self.params.items() if k.startswith('cvect_')}\n",
    "        self.pca_params = {k[4:]:v for k,v in self.params.items() if k.startswith('pca_')}\n",
    "        self.clf_params = {k[4:]:v for k,v in self.params.items() if k.startswith('clf_')}\n",
    "\n",
    "        return self\n",
    "\n",
    "    \n",
    "    def fit_bow(self, keydescriptors):\n",
    "        self.cvect.fit(keydescriptors)\n",
    "        print('BOW fitted')\n",
    "        return self\n",
    "    \n",
    "    def fit_colors(self, colors, samplesize=10000):\n",
    "        colorlist = colors.reshape(-1,3)\n",
    "        indices = np.random.randint(0, colorlist.shape[0], samplesize)\n",
    "        Xsample = colors[indices]\n",
    "        Xscaled = self.color_scaler.fit_transform(Xsample)\n",
    "        self.color_kmeans.fit(Xscaled)\n",
    "        print('Color dominance fitted')\n",
    "        return self\n",
    "    \n",
    "    def transform_bow(self, keydescriptors):\n",
    "        return self.cvect.transform(keydescriptors)\n",
    "    \n",
    "    def fit(self, X, y= None):\n",
    "        sift_desc, color_dominance = self.load_pics(X, y)\n",
    "        self.fit_sift(np.concatenate(sift_desc))\n",
    "        self.fit_colors(np.concatenate(color_dominance))\n",
    "        \n",
    "        bow = self.compute_data(sift_desc, color_dominance)\n",
    "        self.fit_bow(bow)\n",
    "        Xbow = self.transform_bow(bow)\n",
    "        return self\n",
    "    \n",
    "    def color_domincance(self, picture, n_cluster=10):\n",
    "        #Converts to openCV\n",
    "        imcv = cv2.cvtColor(np.array(picture), cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        #Flatten all the pixels\n",
    "        Z = imcv.reshape((-1,3))\n",
    "\n",
    "        # convert to np.float32\n",
    "        Z = np.float32(Z)\n",
    "\n",
    "        # define criteria, number of clusters(K) and apply kmeans()\n",
    "        criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "        K = n_cluster\n",
    "        ret, label, color_dominance = cv2.kmeans(Z,K,None,criteria,10,cv2.KMEANS_RANDOM_CENTERS)\n",
    "        return color_dominance\n",
    "    \n",
    "    def load_pics(self, X, y=None):\n",
    "        sift_desc = []\n",
    "        colors = []\n",
    "        filenames = []\n",
    "        \n",
    "        patch_kw = dict(patch_size=5,      # 5x5 patches\n",
    "                        patch_distance=6,  # 13x13 search area\n",
    "                        multichannel=True)\n",
    "        \n",
    "        for index, picture in X.iterrows():\n",
    "            img = picture.Picture\n",
    "            prepfilename = picture.prepfilename\n",
    "            \n",
    "            temp_img, temp_sift, temp_color = self.treat_pictures(img, prepfilename)\n",
    "            colors.append(temp_color)\n",
    "            sift_desc.append(temp_sift)\n",
    "        \n",
    "        print('Pictures loaded')\n",
    "        \n",
    "        return sift_desc, colors\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        sift_desc, colors = self.load_pics(X, y)\n",
    "        bow = self.compute_data(sift_desc, colors)\n",
    "        Xbow = self.transform_bow(bow)\n",
    "        \n",
    "        return Xbow\n",
    "    \n",
    "    def fit_sift(self, descriptors):\n",
    "        indices = np.random.randint(0,descriptors.shape[0],self.clf_params['kmean_sample_size'])\n",
    "        Xsample = descriptors[indices]\n",
    "        Xscaled = self.scaler.fit_transform(Xsample)\n",
    "        if self.clf_params['apply_pca']:\n",
    "            Xscaled = self.pca.fit_transform(Xscaled)\n",
    "            print('PCA fitted')\n",
    "        else:\n",
    "            print('No PCA')\n",
    "        self.kmeans.fit(Xscaled)\n",
    "        print('Sift fitted')\n",
    "        return self\n",
    "    \n",
    "    def compute_data(self, descriptors, colors):\n",
    "        toreturn = []\n",
    "        for descriptor , color in zip(descriptors, colors):\n",
    "            #Key points treatment\n",
    "            XScaled = self.scaler.transform(descriptor)\n",
    "            if self.clf_params['apply_pca']:\n",
    "                XScaled = self.pca.transform(XScaled)\n",
    "            bow_keys = [self.kmeans.predict(keydescription.reshape(1, -1))[0] for keydescription in XScaled]\n",
    "            keystring = ' '.join(['kp'+str(x) for x in bow_keys])\n",
    "            \n",
    "            #Colors treatment\n",
    "            XScaled = self.color_scaler.transform(color)\n",
    "            bow_colors = [self.color_kmeans.predict(majorcolor.reshape(1, -1))[0] for majorcolor in XScaled]\n",
    "            colorstring = ' '.join(['cl'+str(x) for x in bow_colors])\n",
    "            \n",
    "            toreturn.append(keystring+' '+colorstring) #\n",
    "        return toreturn\n",
    "    \n",
    "    def exportset(self, X):\n",
    "        sift_desc, colors = self.load_pics(X)\n",
    "        bow = self.compute_data(sift_desc, colors)\n",
    "        Xbow = self.transform_bow(bow)\n",
    "        return Xbow\n",
    "    \n",
    "    def treat_pictures(self, picture, prepfilename='zzz'):\n",
    "\n",
    "        imcv = img_as_ubyte(picture)\n",
    "        color_dominance = self.color_domincance(imcv)\n",
    "        imcv_gr = cv2.cvtColor(imcv, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        #print(imcv.shape)\n",
    "        \n",
    "        #plt.imshow(imcv_gr, cmap='gray')\n",
    "        #plt.axis(\"off\")\n",
    "        #plt.show()\n",
    "        \n",
    "        imcv_kp, imcv_desc = self.sift.detectAndCompute(imcv_gr, None)\n",
    "\n",
    "        if self.pics_params['save_pics']:\n",
    "            #Image saving OpenCV\n",
    "            cv2.imwrite('../pics/{}.jpg'.format(prepfilename),cv2.drawKeypoints(imcv, imcv_kp, imcv,flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS))\n",
    "        \n",
    "        return picture, imcv_desc, color_dominance\n",
    "\n",
    "dogreconizer = SiftBOW(**{'pics_save_pics':False, 'clf_apply_pca':False})\n",
    "dogreconizer.get_params()\n",
    "dogreconizer.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogreconizer.get_params()\n",
    "Xbowtrain = dogreconizer.transform(X_train)\n",
    "Xbowtest = dogreconizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('bowsift', Xbowtrain=Xbowtrain.toarray(),\n",
    "                      Xbowtest=Xbowtest.toarray(),\n",
    "                      y_test=y_test,\n",
    "                      y_train=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "zz = np.load('bowsift.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zz['Xbowtrain']\n",
    "zz.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zz['y_train']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogreconizer = SiftBOW(**{'pics_save_pics':True, 'clf_apply_pca':False})\n",
    "clf = RandomForestClassifier()\n",
    "pipe = [('bow', dogreconizer), ('clf',clf)]\n",
    "\n",
    "dogpipe = Pipeline(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogpipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogpipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'bow__color_n_clusters':[30,50], 'bow__kmeans_n_clusters':[30,50], 'clf__n_estimators':[100,200], 'clf__max_depth':[50, None]}\n",
    "\n",
    "dogclf = GridSearchCV(dogpipe, parameters, n_jobs=3, cv=3, verbose=5)\n",
    "\n",
    "dogclf.fit(X_train, y_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogpipe.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier()\n",
    "dogreconizer = SiftBOW(clf, **{'pics_save_pics':True, 'clf_apply_pca':False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX_train = dogreconizer.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = dogreconizer.predict(X_test, y_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogreconizer.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX_test = dogreconizer.exportset(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=12, n_jobs=3)\n",
    "neigh.fit(XX_train.toarray(), y_train.values)\n",
    "neigh.score(XX_test.toarray(), y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'n_neighbors':[3,5,7,9,15,20], 'leaf_size': [10,20,30,40,50]}\n",
    "scorer = make_scorer(f1_score, average='micro')\n",
    "\n",
    "clfknn = GridSearchCV(neigh, parameters, verbose=1, cv=3, n_jobs=5, scoring=scorer)\n",
    "clfknn.fit(XX_train.toarray(), y_train.values)\n",
    "clfknn.score(XX_test.toarray(), y_test.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf = SVC()\n",
    "clf.fit(XX_train.toarray(), y_train.values)\n",
    "clf.score(XX_test.toarray(), y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'C':np.logspace(-5, 5, 11), 'gamma':np.logspace(-5, 5, 11)}\n",
    "scorer = make_scorer(f1_score, average='micro')\n",
    "\n",
    "clfsvc = GridSearchCV(clf, parameters, verbose=1, cv=3, n_jobs=5, scoring=scorer)\n",
    "clfsvc.fit(XX_train.toarray(), y_train.values)\n",
    "clfsvc.score(XX_test.toarray(), y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfsvc.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'n_estimators':[10,50,100,500],\n",
    "              'max_depth':[None,10,15,20],\n",
    "              'min_samples_split':[2,3,5],}\n",
    "scorer = make_scorer(f1_score, average='micro')\n",
    "\n",
    "clfrfc = GridSearchCV(clf, parameters, verbose=1, cv=5, n_jobs=3, scoring=scorer)\n",
    "clfrfc.fit(XX_train.toarray(), y_train.values)\n",
    "clfrfc.score(XX_test.toarray(), y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfrfc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(random_state=0, **clfrfc.best_params_)\n",
    "clf.fit(XX_train.toarray(), y_train.values)\n",
    "clf.feature_importances_\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'n_estimators':[10,50,100,500],\n",
    "              'max_depth':[None,10,15,20],\n",
    "              'min_samples_split':[2,3,5],}\n",
    "scorer = make_scorer(f1_score, average='micro')\n",
    "\n",
    "clfgbc = GridSearchCV(clf, parameters, verbose=1, cv=5, n_jobs=3, scoring=scorer)\n",
    "clfgbc.fit(XX_train.toarray(), y_train.values)\n",
    "clfgbc.score(XX_test.toarray(), y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfgbc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GradientBoostingClassifier(**clfgbc.best_params_)\n",
    "clf.fit(XX_train.toarray(), y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ZCA whitening\n",
    "from keras.datasets import mnist\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib import pyplot\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# reshape to be [samples][pixels][width][height]\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28)\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28)\n",
    "# convert from int to float\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "# define data preparation\n",
    "datagen = ImageDataGenerator(zca_whitening=True)\n",
    "# fit parameters from data\n",
    "datagen.fit(X_train)\n",
    "# configure batch size and retrieve one batch of images\n",
    "for X_batch, y_batch in datagen.flow(X_train, y_train, batch_size=9):\n",
    "    # create a grid of 3x3 images\n",
    "    for i in range(0, 9):\n",
    "        pyplot.subplot(330 + 1 + i)\n",
    "        pyplot.imshow(X_batch[i].reshape(28, 28), cmap=pyplot.get_cmap('gray'))\n",
    "    # show the plot\n",
    "    pyplot.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_train[1].reshape(28, 28), cmap=pyplot.get_cmap('gray'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiftBOW(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, **params):        \n",
    "        self.kmeans_params = {'n_clusters':30, 'verbose':0, 'random_state':3, 'max_iter': 300}\n",
    "        self.sift_params = {'nfeatures':0}\n",
    "        self.pca_params = {'n_components':10, 'random_state':0}\n",
    "        self.cvect_params = {'ngram_range':(1,1), 'min_df':1, 'max_df':1.}\n",
    "        self.color_params = {'n_clusters':30, 'random_state':0}\n",
    "        self.pics_params = {'save_pics':True, 'equalyze':True, }\n",
    "        \n",
    "        self.clf_params = { 'kmean_sample_size':10000}\n",
    "        \n",
    "        self.params = {**{'kmeans_'+k:v for k,v in self.kmeans_params.items()},\n",
    "                       **{'sift_'+k:v for k,v in self.sift_params.items()},\n",
    "                       **{'cvect_'+k:v for k,v in self.cvect_params.items()},\n",
    "                       **{'clf_'+k:v for k,v in self.clf_params.items()},\n",
    "                       **{'pca_'+k:v for k,v in self.pca_params.items()},\n",
    "                       **{'color_'+k:v for k,v in self.color_params.items()},\n",
    "                       **{'pics_'+k:v for k,v in self.pics_params.items()},\n",
    "                       **params}\n",
    "        \n",
    "        self.update_params()\n",
    "        self.kmeans = KMeans(**self.kmeans_params)\n",
    "        self.scaler = StandardScaler()\n",
    "        self.color_scaler = StandardScaler()\n",
    "        self.cvect = CountVectorizer(**self.cvect_params, analyzer='word', tokenizer=None)\n",
    "        self.sift = cv2.xfeatures2d.SIFT_create(**self.sift_params)\n",
    "        #self.sift = cv2.ORB()\n",
    "        self.pca = PCA(**self.pca_params)\n",
    "        self.color_kmeans = KMeans(**self.color_params)\n",
    "        \n",
    "    def get_params(self, deep=True):\n",
    "        return self.params\n",
    "    \n",
    "    def set_params(self, **params):\n",
    "        self.params = {**self.params, **params}\n",
    "        self.update_params()\n",
    "        return self\n",
    "        \n",
    "    def update_params(self):\n",
    "        \n",
    "        self.kmeans_params = {k[7:]:v for k,v in self.params.items() if k.startswith('kmeans_')}\n",
    "        self.sift_params = {k[5:]:v for k,v in self.params.items() if k.startswith('sift_')}\n",
    "        self.pics_params = {k[5:]:v for k,v in self.params.items() if k.startswith('pics_')}\n",
    "        self.color_params = {k[6:]:v for k,v in self.params.items() if k.startswith('color_')}\n",
    "        self.cvect_params = {k[6:]:v for k,v in self.params.items() if k.startswith('cvect_')}\n",
    "        self.pca_params = {k[4:]:v for k,v in self.params.items() if k.startswith('pca_')}\n",
    "        self.clf_params = {k[4:]:v for k,v in self.params.items() if k.startswith('clf_')}\n",
    "\n",
    "        return self\n",
    "\n",
    "    \n",
    "    def fit_bow(self, keydescriptors):\n",
    "        self.cvect.fit(keydescriptors)\n",
    "        print('BOW fitted')\n",
    "        return self\n",
    "    \n",
    "    def fit_colors(self, colors, samplesize=10000):\n",
    "        colorlist = colors.reshape(-1,3)\n",
    "        indices = np.random.randint(0, colorlist.shape[0], samplesize)\n",
    "        Xsample = colors[indices]\n",
    "        Xscaled = self.color_scaler.fit_transform(Xsample)\n",
    "        self.color_kmeans.fit(Xscaled)\n",
    "        print('Color dominance fitted')\n",
    "        return self\n",
    "    \n",
    "    def transform_bow(self, keydescriptors):\n",
    "        return self.cvect.transform(keydescriptors)\n",
    "    \n",
    "    def fit(self, X, y= None):\n",
    "        pics, sift_desc, color_dominance = self.transform(X, y)\n",
    "        self.fit_sift(np.concatenate(sift_desc))\n",
    "        self.fit_colors(np.concatenate(color_dominance))\n",
    "        \n",
    "        bow = self.compute_data(sift_desc, color_dominance)\n",
    "        self.fit_bow(bow)\n",
    "        Xbow = self.transform_bow(bow)\n",
    "        return Xbow\n",
    "    \n",
    "    def color_domincance(self, picture, n_cluster=10):\n",
    "        #Converts to openCV\n",
    "        imcv = cv2.cvtColor(np.array(picture), cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        #Flatten all the pixels\n",
    "        Z = imcv.reshape((-1,3))\n",
    "\n",
    "        # convert to np.float32\n",
    "        Z = np.float32(Z)\n",
    "\n",
    "        # define criteria, number of clusters(K) and apply kmeans()\n",
    "        criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "        K = n_cluster\n",
    "        ret, label, color_dominance = cv2.kmeans(Z,K,None,criteria,10,cv2.KMEANS_RANDOM_CENTERS)\n",
    "        return color_dominance\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        sift_desc = []\n",
    "        colors = []\n",
    "        pics = []\n",
    "        filenames = []\n",
    "        \n",
    "        patch_kw = dict(patch_size=5,      # 5x5 patches\n",
    "                        patch_distance=6,  # 13x13 search area\n",
    "                        multichannel=True)\n",
    "        \n",
    "        for index, picture in X.iterrows():\n",
    "            xmax = picture.xmax\n",
    "            ymax = picture.ymax\n",
    "            xmin = picture.xmin\n",
    "            ymin = picture.ymin\n",
    "            foldername = picture.foldername\n",
    "            breed = picture.breed\n",
    "            filename = picture.filename\n",
    "            prepfilename = picture.prepfilename\n",
    "        \n",
    "            filenames.append(prepfilename)\n",
    "        \n",
    "            #Image opening\n",
    "            img = Image.open('../Images/n{}-{}/{}.jpg'.format(foldername, breed, filename))\n",
    "            \n",
    "            color_dominance = self.color_domincance(img)\n",
    "            \n",
    "            #Image cropping\n",
    "            area = (xmin, ymin, xmax, ymax)\n",
    "            img = img.crop(area)\n",
    "            \n",
    "            #Image equalization\n",
    "            #img = ImageOps.equalize(img)\n",
    "            img = exposure.equalize_hist(np.array(img))\n",
    "            \n",
    "            #Gaussian blur fliter\n",
    "            sigma_est = np.mean(estimate_sigma(np.array(img), multichannel=True, average_sigmas=False))\n",
    "            #print(sigma_est)\n",
    "            #img = img.filter(ImageFilter.GaussianBlur(radius=sigma_est))\n",
    "            #img = gaussian(np.array(img), sigma=sigma_est, multichannel=True)\n",
    "            \n",
    "            #Non linear mean\n",
    "            img = denoise_nl_means(img, h=1.5*sigma_est, fast_mode=True, **patch_kw)\n",
    "            \n",
    "\n",
    "            \n",
    "            temp_img, temp_sift, temp_color = self.treat_pictures(img, prepfilename)\n",
    "            colors.append(temp_color)\n",
    "            pics.append(temp_img)\n",
    "            sift_desc.append(temp_sift)\n",
    "        \n",
    "        print('Pictures loaded')\n",
    "        \n",
    "        return pics, sift_desc, colors\n",
    "    \n",
    "    def predict(self, X, y):\n",
    "        pics, sift_desc, colors = self.transform(X, y)\n",
    "        bow = self.compute_data(sift_desc, colors)\n",
    "        Xbow = self.transform_bow(bow)\n",
    "        \n",
    "        return self.estimator.predict(Xbow)\n",
    "    \n",
    "    def fit_sift(self, descriptors):\n",
    "        indices = np.random.randint(0,descriptors.shape[0],self.clf_params['kmean_sample_size'])\n",
    "        Xsample = descriptors[indices]\n",
    "        Xscaled = self.scaler.fit_transform(Xsample)\n",
    "        if self.clf_params['apply_pca']:\n",
    "            Xscaled = self.pca.fit_transform(Xscaled)\n",
    "            print('PCA fitted')\n",
    "        else:\n",
    "            print('No PCA')\n",
    "        self.kmeans.fit(Xscaled)\n",
    "        print('Sift fitted')\n",
    "        return self\n",
    "    \n",
    "    def compute_data(self, descriptors, colors):\n",
    "        toreturn = []\n",
    "        for descriptor , color in zip(descriptors, colors):\n",
    "            #Key points treatment\n",
    "            XScaled = self.scaler.transform(descriptor)\n",
    "            if self.clf_params['apply_pca']:\n",
    "                XScaled = self.pca.transform(XScaled)\n",
    "            bow_keys = [self.kmeans.predict(keydescription.reshape(1, -1))[0] for keydescription in XScaled]\n",
    "            keystring = ' '.join(['kp'+str(x) for x in bow_keys])\n",
    "            \n",
    "            #Colors treatment\n",
    "            XScaled = self.color_scaler.transform(color)\n",
    "            bow_colors = [self.color_kmeans.predict(majorcolor.reshape(1, -1))[0] for majorcolor in XScaled]\n",
    "            colorstring = ' '.join(['cl'+str(x) for x in bow_colors])\n",
    "            \n",
    "            toreturn.append(keystring+' '+colorstring) #\n",
    "        return toreturn\n",
    "    \n",
    "    def exportset(self, X):\n",
    "        pics, sift_desc, colors = self.transform(X)\n",
    "        bow = self.compute_data(sift_desc, colors)\n",
    "        Xbow = self.transform_bow(bow)\n",
    "        return Xbow\n",
    "    \n",
    "    def treat_pictures(self, picture, prepfilename='zzz'):\n",
    "\n",
    "        imcv = img_as_ubyte(picture)\n",
    "        color_dominance = self.color_domincance(imcv)\n",
    "        imcv_gr = cv2.cvtColor(imcv, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        print(imcv.shape)\n",
    "        \n",
    "        plt.imshow(imcv_gr, cmap='gray')\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "        \n",
    "        imcv_kp, imcv_desc = self.sift.detectAndCompute(imcv_gr, None)\n",
    "\n",
    "        if self.pics_params['save_pics']:\n",
    "            #Image saving OpenCV\n",
    "            cv2.imwrite('../pics/{}.jpg'.format(prepfilename),cv2.drawKeypoints(imcv, imcv_kp, imcv,flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS))\n",
    "        \n",
    "        return picture, imcv_desc, color_dominance\n",
    "\n",
    "dogreconizer = SiftBOW(**{'pics_save_pics':True, 'clf_apply_pca':False})\n",
    "dogreconizer.get_params()\n",
    "dogreconizer.fit(X_train[:5], y_train[:5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
